{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import AnnotationBbox, OffsetImage\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.linalg import norm\n",
    "import scipy as sp\n",
    "from scipy.io import loadmat\n",
    "from sympy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = loadmat('train.mat')['X'].T\n",
    "y = loadmat('train.mat')['y']\n",
    "imagetest = loadmat('test.mat')['X'].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image[:, :, :,1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_stats(X,y,sample_id):\n",
    "    features, labels = X,y\n",
    "\n",
    "    if not (0 <= sample_id < len(features)):\n",
    "        print('{} samples {}.  {} is out of range.'.format(len(features), sample_id))\n",
    "        return None\n",
    "\n",
    "    sample_image = features[sample_id].T\n",
    "    sample_label = labels[sample_id]\n",
    "\n",
    "    print('Example of Image {}:'.format(sample_id))\n",
    "    print('Image - Min Value: {} Max Value: {}'.format(sample_image.min(), sample_image.max()))\n",
    "    print('Image - Shape: {}'.format(sample_image.shape))\n",
    "    print('Label - Label Id: {} '.format(sample_label))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of Image 200:\n",
      "Image - Min Value: 45 Max Value: 242\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: [5] \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ae6abe5f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_stats(image, y, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "Xtrain=image/255\n",
    "Xtest=image/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73257, 3, 32, 32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one-hot encoding of the labels\n",
    "from sklearn import preprocessing\n",
    "\n",
    "labels= np.array(range(np.max(y)))\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(labels)\n",
    "y_oh= lb.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k= np.zeros(shape=(73257, 32, 32, 3))\n",
    "for i, j in enumerate(Xtrain):\n",
    "    k[i]=j.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73257, 32, 32, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain=k\n",
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(Xtrain, y_oh, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14652, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=np.float16(X_train)\n",
    "X_valid=np.float16(X_valid)\n",
    "y_train=np.uint8(y_train)\n",
    "y_valid=np.uint8(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float16')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data={'X_train': X_train, 'X_valid':X_valid, 'y_train':y_train,'y_valid':y_valid}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save data in file\n",
    "np.savez(\"data1.npz\",  X_train= X_train, X_valid=X_valid, y_train=y_train,y_valid=y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X_train', 'y_valid', 'X_valid', 'y_train']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read from file\n",
    "npzfile = np.load(\"data1.npz\")\n",
    "npzfile.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=npzfile['X_train']\n",
    "y_train=npzfile['y_train']\n",
    "X_valid=npzfile['X_valid']\n",
    "y_valid=npzfile['y_valid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=X_train[1:20000]\n",
    "y_train=y_train[1:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19999, 32, 32, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sandra\\Anaconda3\\envs\\tf\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten,Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 2\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(32,32,3),padding='same'))\n",
    "#model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((2, 2),padding='same'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu',padding='same'))\n",
    "#model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "model.add(Dropout(0.5))\n",
    "#model.add(Conv2D(128, (3, 3), activation='relu',padding='same'))\n",
    "#model.add(Activation('relu'))                  \n",
    "#model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='linear'))\n",
    "model.add(Activation('relu'))                  \n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9999 samples, validate on 14652 samples\n",
      "Epoch 1/2\n"
     ]
    }
   ],
   "source": [
    "model_train = model.fit(X_train, y_train, batch_size=batch_size,\n",
    "                        epochs=epochs,verbose=1,validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device: /gpu:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define input\n",
    "def neural_net_image_input(image_shape):\n",
    "\n",
    "    x=tf.placeholder(tf.float32,[None,image_shape[0],image_shape[1],image_shape[2]], name='x')\n",
    "    return x\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "\n",
    "    y = tf.placeholder(tf.float32, [None, n_classes], name='y')\n",
    "    return y\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    return keep_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "\n",
    "    weights = tf.Variable(tf.truncated_normal([conv_ksize[0],conv_ksize[1], \n",
    "                                               x_tensor.get_shape().as_list()[3],conv_num_outputs],stddev=0.08))\n",
    "    bias = tf.Variable(tf.zeros(conv_num_outputs))\n",
    "                          \n",
    "    conv_layer = tf.nn.conv2d(x_tensor, weights, strides=[1, conv_strides[0], conv_strides[1], 1], padding='SAME')\n",
    "    conv_layer = tf.nn.bias_add(conv_layer, bias)\n",
    "    conv_layer=tf.nn.relu(conv_layer)\n",
    "    \n",
    "    output= tf.nn.max_pool(conv_layer, ksize=[1, pool_ksize[0], pool_ksize[1], 1], \n",
    "                           strides=[1, pool_ksize[0], pool_ksize[1], 1], padding='VALID')\n",
    "    return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Flattened Image Size\n",
    "import numpy as np\n",
    "\n",
    "def flatten(x_tensor):\n",
    "    \n",
    "    shape = x_tensor.get_shape().as_list() \n",
    "    dim = np.prod(shape[1:])    \n",
    "    output = tf.reshape(x_tensor, [-1, dim]) \n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "\n",
    "    \n",
    "    flatten_layer = flatten(x_tensor)\n",
    "    \n",
    "    weights = tf.Variable(tf.truncated_normal([flatten_layer.get_shape().as_list()[1],num_outputs], stddev=0.08))\n",
    "    bias = tf.Variable(tf.zeros(num_outputs))\n",
    "    \n",
    "    fc_layer = tf.add(tf.matmul(flatten_layer, weights), bias)\n",
    "    output = tf.nn.relu(fc_layer)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \n",
    "    flatten_layer = flatten(x_tensor)\n",
    "    \n",
    "    weights = tf.Variable(tf.truncated_normal([flatten_layer.get_shape().as_list()[1],num_outputs], stddev=0.08))\n",
    "    bias = tf.Variable(tf.zeros(num_outputs))\n",
    "    \n",
    "    output = tf.add(tf.matmul(flatten_layer, weights), bias)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_net(x, keep_prob,num_classes =10):\n",
    "    \n",
    "    conv1= conv2d_maxpool(x, conv_num_outputs=64,\n",
    "                           conv_ksize=[5,5],\n",
    "                           conv_strides=[1,1],\n",
    "                           pool_ksize=[3,3],\n",
    "                           pool_strides=[2,2])\n",
    "    \n",
    "    conv2= conv2d_maxpool(conv1, 128, [5,5], [1,1], [2,2], [2,2])\n",
    "    #conv3= conv2d_maxpool(conv2, 128, [2,2], [1,1], [2,2], [2,2])\n",
    "\n",
    "    flatten_layer = flatten(conv2)\n",
    "\n",
    "    fc1=fully_conn(flatten_layer, 384)\n",
    "    fc2=fully_conn(fc1, 192)\n",
    "    \n",
    "    fc = tf.nn.dropout(fc2, keep_prob)\n",
    "    out= output(fc, num_classes)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build the Neural Network\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature, label):\n",
    "    session.run(optimizer, feed_dict={x: feature,\n",
    "                                      y: label,\n",
    "                                      keep_prob: keep_probability})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature, label, cost, accuracy):\n",
    "\n",
    "    loss=session.run(cost,feed_dict={x: feature,y: label,keep_prob: 1.})\n",
    "    acc=session.run(accuracy,feed_dict={x: X_valid, y: y_valid, keep_prob: 1.})\n",
    "    \n",
    "    print('Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set parameters\n",
    "epochs = 3\n",
    "batch_size = 64\n",
    "keep_probability = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split features and labels into batches\n",
    "def batch_features_labels(features, labels, batch_size):\n",
    "    for start in range(0, len(features), batch_size):\n",
    "        end = min(start + batch_size, len(features))\n",
    "        yield features[start:end], labels[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        for feature, label in batch_features_labels(X_train,y_train,batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, feature,label)\n",
    "        print('Epoch {:>2}:  '.format(epoch + 1), end='')\n",
    "        print_stats(sess, feature, label, cost, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_image_predictions(features, labels, predictions):\n",
    "    n_classes = 10\n",
    "    label_names = _load_label_names()\n",
    "    label_binarizer = LabelBinarizer()\n",
    "    label_binarizer.fit(range(n_classes))\n",
    "    label_ids = label_binarizer.inverse_transform(np.array(labels))\n",
    "\n",
    "    fig, axies = plt.subplots(nrows=4, ncols=2)\n",
    "    fig.tight_layout()\n",
    "    fig.suptitle('Softmax Predictions', fontsize=20, y=1.1)\n",
    "\n",
    "    n_predictions = 3\n",
    "    margin = 0.05\n",
    "    ind = np.arange(n_predictions)\n",
    "    width = (1. - 2. * margin) / n_predictions\n",
    "\n",
    "    for image_i, (feature, label_id, pred_indicies, pred_values) in enumerate(zip(features, label_ids, predictions.indices, predictions.values)):\n",
    "        pred_names = [label_names[pred_i] for pred_i in pred_indicies]\n",
    "        correct_name = label_names[label_id]\n",
    "\n",
    "        axies[image_i][0].imshow(feature)\n",
    "        axies[image_i][0].set_title(correct_name)\n",
    "        axies[image_i][0].set_axis_off()\n",
    "\n",
    "        axies[image_i][1].barh(ind + margin, pred_values[::-1], width)\n",
    "        axies[image_i][1].set_yticks(ind + margin)\n",
    "        axies[image_i][1].set_yticklabels(pred_names[::-1])\n",
    "        axies[image_i][1].set_xticks([0, 0.5, 1.0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
